{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzcX8e+pqATerL5XaWqx6q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteol1/DeepLearning/blob/main/Image_processing_Simple_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yj9Oiq1TIf7L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image processing - Neural Netowrks"
      ],
      "metadata": {
        "id": "b8jUcjdGIsF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution os a multiplication of two distributionss to smear or highlight features of given data.\n",
        "\n",
        "For example, for images, an equal weight convolution is used to blur  an image.\n",
        "\n",
        "On probablilitydistributions, it averages out the features of the distribution.\n",
        "\n",
        "Convolution is particularly used in learning of images, to. get more efficient trained models."
      ],
      "metadata": {
        "id": "CKcvuRj-Ixpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "#module for [retrained models etc.\n",
        "#import timm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Xk6itFQeIw8Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "Fgzd7fM7m5FZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tools for images and image transofmrmation"
      ],
      "metadata": {
        "id": "-PLaAMbxnMzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforming datasets ->for instance to have images all of the same size and features.\n",
        "\n",
        "For instance, an image will be a tensor of color channels, x pixels on row x pixels on column"
      ],
      "metadata": {
        "id": "gPyN71ctJg3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load **data**"
      ],
      "metadata": {
        "id": "DtHg2V9bIrO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlayingCardsDataset(Dataset):\n",
        "  def __init__(self, data_dir, transform=None):\n",
        "    self.data = ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem(self, index):\n",
        "    return self.data[index]\n",
        "\n",
        "  @property\n",
        "  def classes(self):\n",
        "    return self.data.classes\n"
      ],
      "metadata": {
        "id": "P-Xr2LPCJfhy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = (  data_dir='')"
      ],
      "metadata": {
        "id": "IDNZ2lg6JxGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define dict if needed to map labels to readble output\n",
        "pass"
      ],
      "metadata": {
        "id": "Z0Rylmwnrnvr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define set of transformations to apply to the images"
      ],
      "metadata": {
        "id": "ll_KktqxsdQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor()\n",
        "    ])"
      ],
      "metadata": {
        "id": "k4fiZkelrwwm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7gQRj5kRsQrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoaders"
      ],
      "metadata": {
        "id": "3evEZ-HgsqgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "nx9_Y0o5srfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, labels in dataloader:\n",
        "  break\n",
        "\n",
        "\n",
        "images.shape"
      ],
      "metadata": {
        "id": "_tA7mrvYtBAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define model"
      ],
      "metadata": {
        "id": "xjkJYlrTtTYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the model from scratch or\n",
        "- Load model from module, lie timm"
      ],
      "metadata": {
        "id": "yAZLisXHubb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MySimpleClassifierModel(nn.Module):\n",
        "  def __init__(self, num_classes=53):\n",
        "    #Define parts of the model\n",
        "    #sameple predefined\n",
        "    #self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n",
        "    #enet_out_size = 1280\n",
        "\n",
        "    #Make a classifier\n",
        "    self.classifier = nn.Linear(enet_out_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #Connect parts of the model and produce output\n",
        "    x = self.features(x)\n",
        "    output = self.classifier(x)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "A2QBMB1FtT7X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create training loop"
      ],
      "metadata": {
        "id": "FwbVWXRlwayB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Remember to split the data into a training and a test/validation set.\n",
        "The validation set should not be used for training.\n",
        "\n",
        "Two key components in order to train properly are the:\n",
        "- Optimizer: Adam good example to start with\n",
        "- Loss function: what to optimize for"
      ],
      "metadata": {
        "id": "zXbn0CC9wwgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define instance of the model\n",
        "model = MySimpleClassifierModel(num_classes=53)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "IprU3lAXxl_8",
        "outputId": "d6023f3e-76bf-498f-8dc2-52dad538812f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'enet_out_size' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-8095f2c9ed47>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Define instance of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMySimpleClassifierModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m53\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-f2c4ce425159>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#Make a classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menet_out_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'enet_out_size' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3FDR7m11zU4",
        "outputId": "65a91883-e376-45ec-da84-4ad32ccc0273"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "critetion = nn.CrossEntropyLoss()\n",
        "optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "yb4484xcwc7R",
        "outputId": "c507d74b-9fc9-41c5-f5ab-b52024255fef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8c22ff02a3a7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcritetion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define train and test data\n",
        "#If need be,\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "O6Eos6Hcx4a_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zK7k02g-yjAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, test_losses = [], []"
      ],
      "metadata": {
        "id": "OWMUvF2FyyZG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  #train the model\n",
        "  running_loss = 0.0\n",
        "\n",
        "  #this only needed if data is split in batches\n",
        "  for images, labels in dataloafer:\n",
        "    iamges, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = modeliamges)\n",
        "\n",
        "    loss = criterion(outputs labels)\n",
        "    ;pss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    #only for batches\n",
        "    running_loss = loss.item() * inputs.size(0)\n",
        "\n",
        "  train_loss = running_loss / len(train_loader.dataset)\n",
        "  train_losses.append(train_loss)\n"
      ],
      "metadata": {
        "id": "KYCb2I_ay6Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate losses on validation set\n",
        "\n",
        "model.eval()\n",
        "running_loss = 0.0\n",
        "with torch.no_grad()\n",
        "  for images, labels in val_loader:\n",
        "    iamges, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    #outputs is a numerical label matching the class\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    running_loss = loss.item() * inputs.size(0)\n",
        "\n",
        "  val_loss = running_loss / len(val_loader.dataset)\n",
        "  val_losses.append(val_loss)\n"
      ],
      "metadata": {
        "id": "tqw4G8_B0pHQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}